# Agent Deployment Guide (Fresh Machine)

This guide is for an agent that needs to deploy and run **robotwin-perturbed-bench** on a new machine.

## 1) Mission and success criteria

Your mission:
1. Prepare runtime environment
2. Recreate local dependencies and symlinks
3. Configure policy/model paths
4. Validate installation with smoke tests
5. Run benchmark subset successfully
6. Aggregate results successfully

Success criteria:
- `benchmark/benchmark_spec.json` can be generated
- At least one subset run completes and writes `episode_*.json`
- `summary/*.csv` is generated by aggregate step

---

## 2) Required repositories and expected layout

Use one parent workspace directory:

```text
<WORK_ROOT>/
  robotwin/
  robotwin-perturbed-bench/
  lingbot-va/                  # only needed for LingbotVA policy
  models/                      # optional shared model storage
```

Example:
- `<WORK_ROOT>=/data/code`

Clone commands:

```bash
mkdir -p /data/code
git clone https://github.com/RoboTwin-Platform/RoboTwin.git /data/code/robotwin
git clone https://github.com/WUyinwei-hah/robotwin-perturbed-bench.git /data/code/robotwin-perturbed-bench
# optional
git clone <LINGBOT_VA_REPO_URL> /data/code/lingbot-va
```

---

## 3) Environment preparation

1. Follow RoboTwin official install first:
   - https://robotwin-platform.github.io/doc/usage/robotwin-install.html
2. Ensure ffmpeg exists:

```bash
ffmpeg -version
```

3. Decide python executable and export it:

```bash
export PYTHON=/path/to/python
```

> Important: benchmark scripts default to `/gemini/code/envs/robotwin/bin/python`.
> On fresh machine, always run scripts with `PYTHON=...` override.

---

## 4) Recreate symlinks (MANDATORY)

In benchmark root:

```bash
rm -rf envs task_config assets description script
ln -s ../robotwin/envs envs
ln -s ../robotwin/task_config task_config
ln -s ../robotwin/assets assets
ln -s ../robotwin/description description
ln -s ../robotwin/script script
ls -l envs task_config assets description script
```

If any symlink target is broken, stop and fix workspace layout before proceeding.

---

## 5) Configure policy paths

Edit these files:

- `configs/motus.yml`
  - `robotwin_root`
  - `policy_dir`
  - `checkpoint_path`
  - `wan_path`
  - `vlm_path`
- `configs/pi05.yml`
  - `robotwin_root`
  - `policy_dir`
  - `train_config_name`
  - `model_name`
  - `checkpoint_id`
- `configs/lingbot_va.yml` (if using LingbotVA)
  - `robotwin_root`
  - `lingbot_va_root`
  - `port`

Do not assume default paths are valid on new machine.

---

## 6) Data/model notes

- This benchmark is **evaluation-only**. RoboTwin full dataset is usually not required unless policy runtime explicitly depends on local dataset artifacts.
- RoboTwin dataset (if needed):
  - https://huggingface.co/datasets/TianxingChen/RoboTwin2.0/tree/main/dataset
- Keep large models/datasets outside this repo (e.g., `/data/models`, `/data/datasets`).

---

## 7) Validation checklist (strict order)

Run in `/data/code/robotwin-perturbed-bench` (adjust to your path):

### Step A. Renderer/SAPIEN health

```bash
${PYTHON:-python} -c "from script.test_render import Sapien_TEST; Sapien_TEST()"
```

Expected: prints `Render Well`

### Step B. Generate benchmark spec

```bash
PYTHON=${PYTHON:-python} bash scripts/generate_spec.sh
```

Expected output includes:
- `Settings: 20`
- `Tasks: 50`
- `Total episodes per policy: 5000`

### Step C. Smoke run (small subset)

```bash
PYTHON=${PYTHON:-python} bash scripts/run_motus.sh 0 "scale_lm_always_on" "adjust_bottle"
```

Expected artifacts:
- `results/Motus/scale_lm_always_on/adjust_bottle/episode_0.json` (and more)

### Step D. Aggregate

```bash
PYTHON=${PYTHON:-python} bash scripts/aggregate.sh results summary
```

Expected artifacts:
- `summary/overall.csv`
- `summary/by_setting.csv`
- `summary/aggregate.json`

---

## 8) Full run commands

```bash
# Motus
PYTHON=${PYTHON:-python} bash scripts/run_motus.sh 0

# Pi0.5
PYTHON=${PYTHON:-python} bash scripts/run_pi05.sh 0

# LingbotVA (server must be running first)
PYTHON=${PYTHON:-python} bash scripts/run_lingbot_va.sh 0
```

Resume behavior is enabled automatically (existing `episode_*.json` is skipped).

---

## 9) LingbotVA extra steps

1. Start LingbotVA server first (in lingbot-va repo)
2. Ensure `configs/lingbot_va.yml:port` matches server port
3. Then run `run_lingbot_va.sh`

If blocked/timeouts occur:
- verify server process is alive
- verify port connectivity
- verify prompt/action protocol compatibility

---

## 10) Troubleshooting quick map

- `Render Error`: GPU/driver/display/sapien env issue
- `ModuleNotFoundError: envs`: symlink broken (`envs -> ../robotwin/envs`)
- `checkpoint not found`: wrong paths in `configs/*.yml`
- no episode files generated: check run command filters and runtime errors in console
- aggregate empty: wrong results path or no successful run completed

---

## 11) Agent execution policy

- Do not modify original RoboTwin source unless explicitly requested.
- Do not run destructive git commands.
- Prefer subset smoke run before full benchmark.
- Report exact command + path for every failed step.
- If a prerequisite is missing (model path/server), stop and request user input clearly.
